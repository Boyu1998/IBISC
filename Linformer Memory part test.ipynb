{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attomics import *\n",
    "from json_tools import *\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device= torch.device(\"cuda:1\")\n",
    "\n",
    "# Import data\n",
    "df_mRNA = pd.read_parquet(\"data_attomics/mRNA.parquet\")\n",
    "df_label = pd.read_parquet(\"data_attomics/label.parquet\")\n",
    "\n",
    "# Pick multi-classes data\n",
    "y_tumour = df_label.iloc[:, [0, 2]]\n",
    "\n",
    "# Pick X_train\n",
    "scaler=StandardScaler()\n",
    "X_orignal = df_mRNA.iloc[:,1:df_mRNA.shape[1]]\n",
    "X_scaled = scaler.fit_transform(X_orignal)\n",
    "\n",
    "# Pick y_train\n",
    "y_labels = set(y_tumour['cancer_type'])\n",
    "y_dic = {label: index for index, label in enumerate(sorted(y_labels))}\n",
    "y_numerical = np.array([y_dic[label] for label in y_tumour['cancer_type']])\n",
    "\n",
    "X_train,X_testval,y_train,y_testval=train_test_split(X_scaled, y_numerical, \n",
    "                                                         test_size=0.3,random_state=2, stratify=y_numerical)\n",
    "\n",
    "# Create weight loss function\n",
    "unique, counts = np.unique(y_numerical, return_counts=True)\n",
    "total_count = sum(counts)\n",
    "weights = torch.tensor([total_count / c for c in counts], dtype=torch.float32).to(device)\n",
    "loss_function_weight = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "_,X_train_array,_,y_train_array=train_test_split(X_train, y_train, test_size=512, random_state=2, stratify=y_train)\n",
    "\n",
    "X_train_tensor= torch.tensor(X_train_array)\n",
    "\n",
    "unique,_ = np.unique(y_train, return_counts=True)\n",
    "y_train_tensor = torch.tensor(y_train_array)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "num_classes = len(unique)\n",
    "feature_numbers = X_train_tensor.size(1)\n",
    "\n",
    "# Move to GPU, initial optimizer\n",
    "inputs= X_train_tensor.to(device=device)\n",
    "labels = y_train_tensor.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_group = 4000\n",
    "init_group_size=math.ceil(feature_numbers/n_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AttOmicsEncoder(\n",
    "    in_features=feature_numbers, n_group=n_group, \n",
    "    group_size_list=[math.ceil(init_group_size), math.ceil(init_group_size), math.ceil(init_group_size)],\n",
    "    num_heads=1, flatten_output=True, pe=False, permutation=False, permu_inverse=False, \n",
    "    mem_efficient = True, K_linformer = 2,\n",
    ").to(device)\n",
    "\n",
    "encoder_output_d = math.ceil(init_group_size)\n",
    "\n",
    "head = FullyConnectedNetwork(\n",
    "    [FullyConnectedLayer(input_dim=n_group*encoder_output_d, \n",
    "                         output_dim=math.ceil((n_group* encoder_output_d)/16)),\n",
    "     FullyConnectedLayer(input_dim=math.ceil((n_group* encoder_output_d)/16), \n",
    "                         output_dim=math.ceil((n_group* encoder_output_d)/64))]\n",
    ").to(device)\n",
    "\n",
    "model = AttOmics(encoder=encoder, head=head, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 60000])\n"
     ]
    }
   ],
   "source": [
    "e = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname=f\"Linformer_{n_group}_groups\"\n",
    "#model = encoder\n",
    "\n",
    "def trace_handler(p):\n",
    "    #p.export_memory_timeline(f\"memory_recorder/{modelname}.html\", device=\"cuda:1\")\n",
    "    p.export_memory_timeline(f\"memory_recorder/{modelname}.json\", device=\"cuda:1\")\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    profile_memory=True, \n",
    "    record_shapes=True,\n",
    "    with_stack=True,\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=3,\n",
    "        active=3),\n",
    "    on_trace_ready=trace_handler\n",
    ") as p:\n",
    "    for idx in range(7):\n",
    "        p.step()\n",
    "        e = model(inputs)\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
